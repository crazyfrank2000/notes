# 机器学习框架结构

## 1. 特征工程

特征的组合与选择，特征的离散化与归一化？

特征工程是对原始数据进行一系列工程处理，将其提炼为特征，作为输入供算法和模型使用。是一个表示和展现数据的过程。除去杂质和冗余。

- 结构化数据

- 非结构化数据

  

Normalization特征归一化，为了消除特征之间的量纲影响，使得不同指标之间有可比性。

- 线性函数归一化（Min-Max Sclaing）

  $$X_{norm}=\frac{X-X_{min}}{X_{max}-X_{min}}$$

  

- 零均值归一化（Z-Score Normalization）

  $$ Z= \frac{x-\mu}{\sigma}$$

Categorical Feature

- Ordinal Encoding
- One hot encoding
- Binary Encoding

高阶组合特征

组合特征

文本处理

	- bag of words
	- TF-IDF
	- Topic Model
	- Word Embedding

word2Vec 是目前常用的词语嵌入模型之一。是一种浅层的神经网络模型。有两种网络结构，CBOW，Skipgram

在机器学习中，遇到训练数据不足的问题，如图像处理，与分类。Transfer Learning，生成对抗网络，图像处理，上采样技术，数据扩充

----



## 2. 模型评估

离线评估，和在线评估两个阶段。对分类，排序，回归，序列预测等不同的问题，评估的指标也有不同。

Accuracy, precision, recall , root mean square error

召回率是分类正确的正样本个数占真正的正样本个数的比例。

余弦距离的相似度

$$cos(A,B)=\frac{A*B}{||A||_{2}||B||_{2}} $$

欧士距离



A/B 􏷮􏴇􏰔􏳟􏵓􏰣􏱚􏴛􏹿􏷪􏴾􏰉􏷯􏱘 􏲰􏶔􏰙测试是验证模型效果是否好，原因如下：

1. 􏹵􏰛􏻛􏺈􏶸􏰅􏴎􏱆􏸃􏱂􏰣􏱚􏳜􏳞􏵌􏰉􏶡􏴕􏹵􏰛􏻛􏺈􏶸􏰅􏴎􏱆􏸃􏱂􏰣􏱚􏳜􏳞􏵌􏰉􏶡􏴕􏹵􏰛􏻛􏺈􏶸􏰅􏴎􏱆􏸃􏱂􏰣􏱚􏳜􏳞􏵌􏰉􏶡􏴕离线评估无法完全消除模型过拟合的影响
2. 离线评估无法完全还原线上的工程环境
3. 线上心头的某些上衣指标在离线评估中无法计算

如何进行A/B测试􏰐􏷝

进行A/B测试主要是进行用户分桶，即将用户分成实验组和对照组。实验组的用户使用新模型，对照组的用户是以旧模型。

􏰐􏷝􏴚􏹸􏰞􏻮􏱔􏰩􏰋􏲝􏱒􏺫􏳸􏼇􏵮􏹁􏼈􏼉􏱶􏱈􏰼􏰀􏼉􏱶􏱈􏼊􏺗􏼋􏱔􏷗􏶊 􏰄超参数调优，一般会采用网格搜索，随机搜索，贝叶斯优化等。



降低过拟合风险的方法

1. 获得更多的训练数据

2. 降低模型复杂度

3. 正则化方法，给模型的参数加上一定的正则约束，比如将权重的大小加入到损失函数中

4. 集成学习方法，如bagging

   􏷮􏱘􏲰􏶔􏰔􏰐􏷝􏵮􏲗􏲁􏳆􏰩􏺮􏰷􏵮􏲗􏲁􏱑􏲎􏳟􏵗􏳴􏱙􏹥􏵗􏰩􏱙 􏲎􏳟􏵗􏰉􏵮􏲗􏲉􏰪􏴑

----





## 3. 优化算法



## 4. 数据基础

## 5. 机器学习基本概念

## 6. 经典机器模型

1. 支持向量机SVM

   SVM模型推导，核函数，SMO（Sequential Mini Opt)

   KKT 条件

   $$ \nabla_{w}L(w^*,\beta^*,\alpha^*) = w^* - \sum_{i=1}^N\alpha_{i}^*y_{i}x_{i}=0 $$

   

   对于不相交的两个凸集，存在一个超平面，将两个凸集分离，对二维，两个凸集的距离最短两点连线的中垂线就是一个可以将它们分离的超平面

   

2. 逻辑回归

   softmax

   逻辑回归是处理分类问题，线性回归是处理回归问题。

   逻辑回归，因变量取值是一个二元分布，模型学习得出的是$E[y|x;\theta]$ 

   即给定自变量和超参数后，得到因变量的期望，并基于此期望处理预测分类问题

   逻辑回归公式，得到$log \frac{p}{1-p}=\theta^Tx$

   如果把一件事件的几率定义为该事件发生的概率与该事件不发生的概率比值，那么逻辑回归可以看作死对于 y=1|x 这件事情的对数几率的线性回归

   逻辑回归可以看作广义线性模型（GLM）在因变量y服从二元分布的一个特殊情况

   

3. 决策树

   决策树是一种自上而下，对样本数据进行树形分类的过程，由结点和有向边组成。结点分为内部节点和叶节点，其中每个内部节点表示一个特征或者属性，叶节点表示分类。从顶部节点开始，所有样本聚在一起，经过根节点的划分，样本被分到不同的子节点中。再根据子节点的特征进一步划分，直至所有样本都被规划到某一个类别中。

   随机森林，梯度提升决策树，

   决策树的生成包含，特征选择，树的构造，树的剪枝三个过程。

   决策树构造使用时候的准则：

   ID3，C4.5，CART

   - ID3 最大信息增益 g(D,A) = H(D)-H(D|A)
   - C4.5 最大信息增益比
   - CART 最大吉尼指数

   

## 7.深度学习模型

## 8.工程能力

## 9.业务与应用



